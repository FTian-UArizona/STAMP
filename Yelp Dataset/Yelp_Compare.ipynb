{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyP5MNFK5RgWjJejH3QHhvpo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"opy49YOY1Pqy"},"outputs":[],"source":["# Library\n","\n","import torch\n","import math\n","import re\n","import numpy as np\n","import pandas as pd\n","from torch.distributions import Laplace\n","\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoModelForCausalLM\n","from transformers import GPT2LMHeadModel\n","from transformers import AutoModelForSequenceClassification\n","\n","from datasets import load_dataset\n","from sentence_transformers import SentenceTransformer, util\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from scipy.stats import vonmises_fisher\n","import torch.nn.functional as F\n","\n","from typing import Dict, List, Optional\n","\n","from openai import OpenAI\n","import glob\n","\n","from collections import Counter\n","\n","from sentence_transformers import SentenceTransformer\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["# Run once per notebook\n","import shutil, matplotlib as mpl\n","\n","USE_TEX = shutil.which(\"latex\") is not None   # auto-detect; False on Colab by default\n","mpl.rcParams.update({\"text.usetex\": USE_TEX, \"axes.unicode_minus\": False})\n","\n","if USE_TEX:\n","    # Real LaTeX path (if you *do* have TeX available)\n","    mpl.rcParams.update({\n","        \"font.family\": \"serif\",\n","        \"font.serif\": [\"Computer Modern Roman\", \"CMU Serif\", \"Times New Roman\", \"DejaVu Serif\"],\n","        \"text.latex.preamble\": r\"\\usepackage{amsmath}\\usepackage{bm}\\usepackage{siunitx}\"\n","    })\n","else:\n","    # LaTeX-like look without LaTeX installed\n","    mpl.rcParams.update({\n","        \"text.usetex\": False,\n","        # Use a LaTeX-y serif + STIX math (good match for LaTeX/Times);\n","        # if you prefer Computer Modern look, change 'stix' -> 'cm'\n","        \"font.family\": \"serif\",\n","        \"font.serif\": [\"STIX Two Text\", \"STIXGeneral\", \"DejaVu Serif\", \"Times New Roman\"],\n","        \"mathtext.fontset\": \"stix\",\n","        \"mathtext.rm\": \"serif\",\n","        \"mathtext.it\": \"serif:italic\",\n","        \"mathtext.bf\": \"serif:bold\",\n","    })"],"metadata":{"id":"NMU-ons3_6kB","executionInfo":{"status":"aborted","timestamp":1763767063178,"user_tz":420,"elapsed":33,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f9fffe1f","executionInfo":{"status":"aborted","timestamp":1763767063178,"user_tz":420,"elapsed":22,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["client = OpenAI(api_key=\"Your_API_Key\")  # needs OPENAI_API_KEY\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Load tokenizer and GPT-2 model ---\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\", output_hidden_states=True)\n","embedding_table = model.get_input_embeddings().weight.detach()\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","model.eval()\n","\n","# Base tokenizer pad fix (optional)\n","if getattr(tokenizer, \"pad_token_id\", None) is None and getattr(tokenizer, \"eos_token\", None) is not None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# Load a light GPT-2 model\n","gpt2_tok = AutoTokenizer.from_pretrained(\"distilgpt2\")\n","if gpt2_tok.pad_token is None:\n","    gpt2_tok.pad_token = gpt2_tok.eos_token\n","gpt2_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(\n","    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",").eval()\n","\n","# --- Extract embedding table ---\n","# Normalize embedding table for search\n","norm_embedding_table = torch.nn.functional.normalize(embedding_table, dim=1)"],"metadata":{"id":"YZecP5w2lVxq","executionInfo":{"status":"aborted","timestamp":1763767063179,"user_tz":420,"elapsed":23,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sOYdjIRM06O9","executionInfo":{"status":"aborted","timestamp":1763767063189,"user_tz":420,"elapsed":32,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f92cdee9","executionInfo":{"status":"aborted","timestamp":1763767063190,"user_tz":420,"elapsed":33,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# --- load all STAMP_Polar and STAMP_Laplace datasets ---\n","csv_files_polar_inf = glob.glob(\"/content/yelp_inf_polar_sweep_avg_epsilon_*.csv\") # Changed to yelp\n","csv_files_laplace_inf = glob.glob(\"/content/yelp_inf_laplace_sweep_avg_epsilon_*.csv\") # Changed to yelp\n","\n","csv_files = csv_files_polar_inf + csv_files_laplace_inf\n","print(\"Files found by glob:\", csv_files)\n","\n","dataframes = {}\n","\n","for file in csv_files:\n","    df_name = file.replace(\".csv\", \"\")\n","    dataframes[df_name] = pd.read_csv(file)\n","\n","print(\"Number of dataframes loaded:\", len(dataframes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-3JY7x-iVbPC","executionInfo":{"status":"aborted","timestamp":1763767063191,"user_tz":420,"elapsed":14,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3356ff3a","executionInfo":{"status":"aborted","timestamp":1763767063192,"user_tz":420,"elapsed":15,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Get the answers\n","\n","def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        return re.sub(r'[^\\w\\s]', '', text)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def get_tokens(s):\n","    if not s: return []\n","    return normalize_answer(s).split()\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = get_tokens(prediction)\n","    truth_tokens = get_tokens(truth)\n","\n","    # if either is empty, return 1 if both are empty, 0 otherwise\n","    if not pred_tokens and not truth_tokens:\n","        return 1.0\n","    if not pred_tokens or not truth_tokens:\n","        return 0.0\n","\n","    common_tokens = Counter(pred_tokens) & Counter(truth_tokens)\n","    num_common = sum(common_tokens.values())\n","\n","    if num_common == 0:\n","        return 0.0\n","\n","    precision = num_common / len(pred_tokens)\n","    recall = num_common / len(truth_tokens)\n","\n","    return (2 * precision * recall) / (precision + recall)\n","\n","def evaluate_answer(predicted_answer: str, true_answers: list[str]):\n","    \"\"\"\n","    Evaluates a predicted answer against a list of true answers using F1 score and exact match.\n","\n","    Args:\n","        predicted_answer: The generated answer string.\n","        true_answers: A list of true answer strings.\n","\n","    Returns:\n","        A tuple containing:\n","            - The maximum F1 score achieved against any of the true answers.\n","            - A boolean indicating whether an exact match was found against any of the true answers.\n","    \"\"\"\n","    max_f1 = 0.0\n","    exact_match = False\n","\n","    normalized_prediction = normalize_answer(predicted_answer)\n","\n","    for true_answer in true_answers:\n","        normalized_true = normalize_answer(true_answer)\n","\n","        # Exact Match\n","        if normalized_prediction == normalized_true:\n","            exact_match = True\n","\n","        # F1 Score\n","        f1 = compute_f1(predicted_answer, true_answer)\n","        max_f1 = max(max_f1, f1)\n","\n","    return max_f1, exact_match\n","\n","\n","def calculate_cosine_similarity(prediction: str, truths: list[str], model) -> float:\n","    \"\"\"\n","    Calculates the cosine similarity between the prediction and each true answer\n","    using Sentence-BERT embeddings and returns the maximum similarity.\n","    \"\"\"\n","    if not prediction or not truths:\n","        return 0.0\n","\n","    # Encode the prediction\n","    prediction_embedding = model.encode(prediction, convert_to_tensor=True)\n","\n","    max_similarity = 0.0\n","    for truth in truths:\n","        if not truth:\n","            continue\n","        # Encode the true answer\n","        truth_embedding = model.encode(truth, convert_to_tensor=True)\n","\n","        # Calculate cosine similarity\n","        similarity = util.pytorch_cos_sim(prediction_embedding, truth_embedding).item()\n","        max_similarity = max(max_similarity, similarity)\n","\n","    return max_similarity\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b620167e","executionInfo":{"status":"aborted","timestamp":1763767063192,"user_tz":420,"elapsed":13,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Initialize Sentence Transformer model\n","model_sentence = SentenceTransformer('all-MiniLM-L6-v2')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07c479d9","executionInfo":{"status":"aborted","timestamp":1763767063193,"user_tz":420,"elapsed":3,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}},"collapsed":true},"source":["\n","# Load kmack Yelp classifier\n","tokenizer = AutoTokenizer.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","\n","num_rounds = 3\n","all_results = []\n","\n","for round_num in range(num_rounds):\n","    print(f\"--- Starting Round {round_num + 1}/{num_rounds} ---\")\n","    results_list = []\n","\n","    for df_name, df in dataframes.items():\n","        print(f\"Processing DataFrame: {df_name}\")\n","        for index, row in df.iterrows():\n","            question = row[\"question\"]\n","            true_answers = [str(row[\"rating\"])]  # Assuming 'rating' column holds gold label\n","            privatized_context = row[\"privatized_context\"]\n","            original_context = row[\"original_context\"]\n","\n","            try:\n","                # Encode privatized context\n","                inputs = tokenizer(privatized_context, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","                # Run classification\n","                with torch.no_grad():\n","                    outputs = model(**inputs)\n","                predicted_label = torch.argmax(outputs.logits, dim=1).item()\n","\n","                # Store as string for comparison\n","                answer_privatized = str(predicted_label)\n","\n","            except Exception as e:\n","                print(f\"Error running classifier: {e}\")\n","                answer_privatized = \"\"\n","\n","            # Evaluate answer\n","            f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","\n","            results_list.append({\n","                \"dataframe\": df_name,\n","                \"question\": question,\n","                \"true_answers\": true_answers,\n","                \"original_context\": original_context,\n","                \"privatized_context\": privatized_context,\n","                \"answer_privatized\": answer_privatized,\n","                \"f1_privatized\": f1_privatized,\n","                \"em_privatized\": em_privatized,\n","            })\n","\n","    df_round_results = pd.DataFrame(results_list)\n","    all_results.append(df_round_results)\n","\n","print(f\"\\nFinished {num_rounds} rounds of evaluation.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenate all results DataFrames into a single DataFrame\n","df_all_results_combined = pd.concat(all_results, ignore_index=True)\n","\n","# Save the combined DataFrame to a CSV file\n","csv_output_path = \"Yelp_evaluation_results_inf_rounds.csv\"\n","df_all_results_combined.to_csv(csv_output_path, index=False)\n","\n","print(f\"All evaluation results saved to {csv_output_path}\")"],"metadata":{"id":"LlixS32lwJxV","executionInfo":{"status":"aborted","timestamp":1763767063201,"user_tz":420,"elapsed":10,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c61d7c8d","executionInfo":{"status":"aborted","timestamp":1763767063202,"user_tz":420,"elapsed":10,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Load the Yelp GPT-4 Fill dataset\n","file_path_yelp_gpt4_fill = \"/content/yelp_gpt4_fill_tau_0.5.csv\" # Assuming this is the correct filename based on available files\n","try:\n","    df_yelp_gpt4_fill = pd.read_csv(file_path_yelp_gpt4_fill)\n","    print(f\"Loaded dataset: {file_path_yelp_gpt4_fill}\")\n","    display(df_yelp_gpt4_fill.head())\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {file_path_yelp_gpt4_fill}\")\n","    df_yelp_gpt4_fill = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ee3278d","executionInfo":{"status":"aborted","timestamp":1763767063202,"user_tz":420,"elapsed":9,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Load the kmack Yelp Review Classifier\n","tokenizer = AutoTokenizer.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","\n","if df_yelp_gpt4_fill is not None:\n","    results_list_yelp_gpt4_fill = []\n","\n","    for index, row in df_yelp_gpt4_fill.iterrows():\n","        question = row[\"question\"]  # Not used by classifier\n","        true_rating_original = row[\"rating\"]  # 0–4 rating scale\n","        true_answers = [str(true_rating_original)]  # for evaluate_answer()\n","\n","        privatized_context = row[\"privatized_context_gpt4_fill\"]\n","\n","        try:\n","            # Encode privatized context\n","            inputs = tokenizer(privatized_context, return_tensors=\"pt\", truncation=True, padding=True)\n","\n","            # Run classification\n","            with torch.no_grad():\n","                outputs = model(**inputs)\n","            predicted_label = torch.argmax(outputs.logits, dim=1).item()\n","\n","            # Map to string\n","            answer_privatized = str(predicted_label)\n","\n","        except Exception as e:\n","            print(f\"Error running kmack/YELP-Review_Classifier on row {index}: {e}\")\n","            answer_privatized = \"\"\n","\n","        # Evaluate predicted label vs. true rating\n","        f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","\n","        results_list_yelp_gpt4_fill.append({\n","            \"question\": question,\n","            \"true_rating\": true_rating_original,\n","            \"true_answers\": true_answers,\n","            \"privatized_context\": privatized_context,\n","            \"predicted_sentiment_label\": answer_privatized,\n","            \"f1_privatized\": f1_privatized,\n","            \"em_privatized\": em_privatized,\n","        })\n","\n","    # Convert results list to DataFrame\n","    df_yelp_gpt4_fill_results = pd.DataFrame(results_list_yelp_gpt4_fill)\n","    display(df_yelp_gpt4_fill_results.head())\n","\n","    # Compute average scores\n","    average_scores_yelp_gpt4_fill = {\n","        'mean_f1_privatized_kmack': df_yelp_gpt4_fill_results['f1_privatized'].mean(),\n","        'mean_em_privatized_kmack': df_yelp_gpt4_fill_results['em_privatized'].mean(),\n","    }\n","    df_average_scores_yelp_gpt4_fill = pd.DataFrame([average_scores_yelp_gpt4_fill])\n","    display(df_average_scores_yelp_gpt4_fill)\n","\n","    # Save results\n","    csv_output_path_yelp_gpt4_fill = \"yelp_gpt4_fill_kmack_results.csv\"\n","    df_yelp_gpt4_fill_results.to_csv(csv_output_path_yelp_gpt4_fill, index=False)\n","\n","    print(f\"Evaluation results for Yelp GPT-4 Fill with kmack/YELP-Review_Classifier saved to {csv_output_path_yelp_gpt4_fill}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uXQQeDecAIrs","executionInfo":{"status":"aborted","timestamp":1763767063275,"user_tz":420,"elapsed":74,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load all CSV files in /content/\n","\n","csv_files = glob.glob(\"/content/*.csv\")\n","print(f\"Found {len(csv_files)} CSV files in /content/: {csv_files}\")\n","\n","dataframes = {}\n","for file in csv_files:\n","    try:\n","        df_name = file.replace(\"/content/\", \"\").replace(\".csv\", \"\")\n","        dataframes[df_name] = pd.read_csv(file)\n","        print(f\"Successfully loaded {file} into dataframe '{df_name}'\")\n","        display(dataframes[df_name].head()) # Display the head of the dataframe\n","    except Exception as e:\n","        print(f\"Error loading {file}: {e}\")\n","\n","print(f\"✅ Number of dataframes loaded: {len(dataframes)}\")"],"metadata":{"id":"I50V1DfbAIub","executionInfo":{"status":"aborted","timestamp":1763767063276,"user_tz":420,"elapsed":73,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-91jSKrkAIwl","executionInfo":{"status":"aborted","timestamp":1763767063277,"user_tz":420,"elapsed":0,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 7))\n","\n","# Inf Laplace\n","df_laplace = df_aggregated_inf_metrics[df_aggregated_inf_metrics['method'] == 'Inf Laplace']\n","plt.plot(df_laplace['epsilon'], df_laplace['mean_accuracy'],\n","         label='Inf Laplace', marker='o', linestyle='-')\n","\n","# Inf Polar\n","df_polar = df_aggregated_inf_metrics[df_aggregated_inf_metrics['method'] == 'Inf Polar']\n","plt.plot(df_polar['epsilon'], df_polar['mean_accuracy'],\n","         label='Inf Polar', marker='o', linestyle='--')\n","\n","# Baseline (kmack classifier)\n","if 'average_scores_yelp_gpt4_fill' in globals() and \\\n","   'mean_em_privatized_kmack' in average_scores_yelp_gpt4_fill:\n","    baseline_acc = average_scores_yelp_gpt4_fill['mean_em_privatized_kmack']\n","    plt.axhline(y=baseline_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill)')\n","    print(f\"Baseline accuracy (kmack): {baseline_acc:.3f}\")\n","else:\n","    print(\"⚠️ Baseline accuracy not found — check variable name!\")\n","\n","plt.title('Accuracy vs. Epsilon')\n","plt.xlabel('Epsilon')\n","plt.ylabel('Accuracy (Exact Match)')\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend(title='Method')\n","plt.show()\n"],"metadata":{"id":"aehRqvpDjMkx","executionInfo":{"status":"aborted","timestamp":1763767063277,"user_tz":420,"elapsed":13938,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4c14b952","executionInfo":{"status":"aborted","timestamp":1763767063278,"user_tz":420,"elapsed":13938,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Process the 'Yelp_evaluation_results_inf_rounds' dataframe\n","df_inf_results = dataframes['Yelp_evaluation_results_inf_rounds'].copy()\n","\n","# Extract epsilon from filename\n","df_inf_results['epsilon'] = df_inf_results['dataframe'].apply(\n","    lambda x: float(x.split('_')[-1]) # Assuming filenames like ..._200.00, ..._400.00\n",")\n","\n","# Add method column (Laplace or Polar)\n","df_inf_results['method'] = df_inf_results['dataframe'].apply(\n","    lambda x: 'Inf Laplace' if 'laplace' in x.lower() else 'Inf Polar'\n",")\n","\n","# Aggregate mean accuracy by epsilon + method\n","df_aggregated_inf_metrics = (\n","    df_inf_results.groupby(['epsilon', 'method'])\n","    .agg(mean_accuracy=('em_privatized', 'mean'))\n","    .reset_index()\n","    .sort_values('epsilon')\n",")\n","\n","display(df_aggregated_inf_metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","import matplotlib.pyplot as plt\n","\n","# --- 1) Non-private Yelp baseline (first 50 test samples) ---\n","yelp = load_dataset(\"yelp_review_full\", split=\"test[:50]\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","\n","correct = 0\n","for example in yelp:\n","    text = example[\"text\"]\n","    true_label = example[\"label\"]\n","    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    pred = torch.argmax(outputs.logits, dim=1).item()\n","    if pred == true_label:\n","        correct += 1\n","\n","baseline_yelp50_acc = correct / len(yelp)\n","print(f\"Baseline (Non-Private)): {baseline_yelp50_acc:.3f}\")\n","\n","# --- 2) Inf Laplace & Inf Polar curves ---\n","plt.figure(figsize=(12, 7))\n","\n","df_laplace = df_aggregated_inf_metrics[df_aggregated_inf_metrics['method'] == 'Inf Laplace']\n","plt.plot(df_laplace['epsilon'], df_laplace['mean_accuracy'],\n","         label='Inf Laplace', marker='o', linestyle='-')\n","\n","df_polar = df_aggregated_inf_metrics[df_aggregated_inf_metrics['method'] == 'Inf Polar']\n","plt.plot(df_polar['epsilon'], df_polar['mean_accuracy'],\n","         label='Inf Polar', marker='o', linestyle='--')\n","\n","# --- 3) GPT-4 Fill + kmack classifier baseline ---\n","if 'average_scores_yelp_gpt4_fill' in globals() and 'mean_em_privatized_kmack' in average_scores_yelp_gpt4_fill:\n","    baseline_gpt4fill_acc = average_scores_yelp_gpt4_fill['mean_em_privatized_kmack']\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='(GPT-4 Fill')\n","    print(f\"GPT-4 Fill: {baseline_gpt4fill_acc:.3f}\")\n","else:\n","    print(\"GPT-4 Fill baseline not found.\")\n","\n","# --- 4) Non-private Yelp test baseline (first 50 samples) ---\n","plt.axhline(y=baseline_yelp50_acc, color='green', linestyle='-.', linewidth=2,\n","            label='Baseline (Non-Private)')\n","\n","# --- Style ---\n","plt.title('Accuracy vs. Epsilon')\n","plt.xlabel('Epsilon')\n","plt.ylabel('Accuracy (Exact Match)')\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend(title='Method')\n","plt.show()\n"],"metadata":{"id":"Z3Ns6V2ejMnQ","executionInfo":{"status":"aborted","timestamp":1763767063278,"user_tz":420,"elapsed":13937,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Cm3MKTe2jMpz","executionInfo":{"status":"aborted","timestamp":1763767063279,"user_tz":420,"elapsed":13937,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0urh5tIsjMsV","executionInfo":{"status":"aborted","timestamp":1763767063279,"user_tz":420,"elapsed":13936,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jUJDqIMEjMup","executionInfo":{"status":"aborted","timestamp":1763767063279,"user_tz":420,"elapsed":13935,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10d51834","executionInfo":{"status":"aborted","timestamp":1763767063280,"user_tz":420,"elapsed":13935,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# --- load all STAMP_Polar and STAMP_Laplace datasets ---\n","csv_files_polar = glob.glob(\"/content/yelp_stamp_polar_sweep_avg_epsilon_*.csv\") # Changed to yelp\n","csv_files_laplace = glob.glob(\"/content/yelp_stamp_Laplace_sweep_avg_epsilon_*.csv\") # Changed to yelp\n","\n","csv_files = csv_files_polar + csv_files_laplace\n","print(\"Files found by glob:\", csv_files)\n","\n","dataframes = {}\n","\n","for file in csv_files:\n","    df_name = file.replace(\".csv\", \"\")\n","    dataframes[df_name] = pd.read_csv(file)\n","\n","print(\"Number of dataframes loaded:\", len(dataframes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"23d172a1","executionInfo":{"status":"aborted","timestamp":1763767063285,"user_tz":420,"elapsed":13939,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Load classifier\n","tokenizer = AutoTokenizer.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","\n","num_rounds = 3\n","all_results_non_inf = []\n","\n","for round_num in range(num_rounds):\n","    print(f\"--- Starting Round {round_num + 1}/{num_rounds} ---\")\n","    results_list = []\n","\n","    for df_name, df in dataframes.items():  # Use the STAMP non-inf dataframes\n","        print(f\"Processing DataFrame: {df_name}\")\n","\n","        for index, row in df.iterrows():\n","            question = row[\"question\"]\n","            true_answers = [str(row[\"rating\"])]  # True label as string\n","\n","            privatized_context = row.get(\"privatized_context\", \"\")\n","            original_context = row.get(\"original_context\", \"\")  # <-- safely get original if available\n","\n","            # --- Classify privatized context ---\n","            try:\n","                inputs = tokenizer(privatized_context, return_tensors=\"pt\", truncation=True, padding=True)\n","                with torch.no_grad():\n","                    outputs = model(**inputs)\n","                pred_label = torch.argmax(outputs.logits, dim=1).item()\n","                answer_privatized = str(pred_label)\n","            except Exception as e:\n","                print(f\"Error classifying privatized context row {index}: {e}\")\n","                answer_privatized = \"\"\n","\n","            # Evaluate privatized\n","            f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","            cosine_privatized = calculate_cosine_similarity(answer_privatized, true_answers, model_sentence)\n","\n","            # --- Store results, now with original + privatized ---\n","            results_list.append({\n","                \"dataframe\": df_name,\n","                \"question\": question,\n","                \"true_answers\": true_answers,\n","                \"original_context\": original_context,        # <-- added\n","                \"privatized_context\": privatized_context,    # <-- keep\n","                \"answer_privatized\": answer_privatized,\n","                \"f1_privatized\": f1_privatized,\n","                \"em_privatized\": em_privatized,\n","                \"cosine_privatized\": cosine_privatized,\n","            })\n","\n","    # Store round results\n","    df_round_results = pd.DataFrame(results_list)\n","    all_results_non_inf.append(df_round_results)\n","\n","print(f\"\\nFinished {num_rounds} rounds of evaluation for non-inf files.\")\n","\n","# Combine all rounds\n","df_all_results_combined_non_inf = pd.concat(all_results_non_inf, ignore_index=True)\n","\n","# Save to CSV\n","csv_output_path_non_inf = \"Yelp_evaluation_results_non_inf_STAMP_rounds.csv\"\n","df_all_results_combined_non_inf.to_csv(csv_output_path_non_inf, index=False)\n","\n","print(f\"All evaluation results for non-inf files saved to {csv_output_path_non_inf}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0571c73","executionInfo":{"status":"aborted","timestamp":1763767063285,"user_tz":420,"elapsed":13938,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# Load the combined evaluation results for non-inf files from CSV\n","csv_output_path_non_inf = \"Yelp_evaluation_results_non_inf_STAMP_rounds.csv\"\n","try:\n","    df_all_results_combined_non_inf = pd.read_csv(csv_output_path_non_inf)\n","    print(f\"Successfully loaded data from {csv_output_path_non_inf}\")\n","    display(df_all_results_combined_non_inf.head())\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {csv_output_path_non_inf}. Please ensure cell 23d172a1 was executed successfully.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cd5567f9","executionInfo":{"status":"aborted","timestamp":1763767063286,"user_tz":420,"elapsed":13938,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["# --- Prepare Data ---\n","# Extract epsilon from filename\n","df_all_results_combined_non_inf['epsilon'] = df_all_results_combined_non_inf['dataframe'].apply(\n","    lambda x: float(x.split('_')[-1])  # assumes filenames like ..._200, ..._400\n",")\n","\n","# Add method column (Laplace or Polar)\n","df_all_results_combined_non_inf['method'] = df_all_results_combined_non_inf['dataframe'].apply(\n","    lambda x: 'STAMP Laplace' if 'laplace' in x.lower() else 'STAMP Polar'\n",")\n","\n","# Aggregate mean accuracy by epsilon + method\n","df_agg_non_inf = (\n","    df_all_results_combined_non_inf.groupby(['epsilon', 'method'])\n","    .agg(mean_accuracy=('em_privatized', 'mean'))\n","    .reset_index()\n","    .sort_values('epsilon')\n",")\n","\n","display(df_agg_non_inf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KTbsDJvtASpq","executionInfo":{"status":"aborted","timestamp":1763767063286,"user_tz":420,"elapsed":13937,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"YqTLIZsbASsI","executionInfo":{"status":"aborted","timestamp":1763767063287,"user_tz":420,"elapsed":13937,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Prepare Data ---\n","# Extract epsilon from filename\n","df_all_results_combined_non_inf['epsilon'] = df_all_results_combined_non_inf['dataframe'].apply(\n","    lambda x: float(x.split('_')[-1])  # assumes filenames like ..._200, ..._400\n",")\n","\n","# Add method column (Laplace or Polar)\n","df_all_results_combined_non_inf['method'] = df_all_results_combined_non_inf['dataframe'].apply(\n","    lambda x: 'STAMP Laplace' if 'laplace' in x.lower() else 'STAMP Polar'\n",")\n","\n","# Aggregate mean accuracy by epsilon + method\n","df_agg_non_inf = (\n","    df_all_results_combined_non_inf.groupby(['epsilon', 'method'])\n","    .agg(mean_accuracy=('em_privatized', 'mean'))\n","    .reset_index()\n","    .sort_values('epsilon')\n",")\n","\n","# --- Plot ---\n","plt.figure(figsize=(8, 5))\n","\n","# STAMP Polar\n","df_polar = df_agg_non_inf[df_agg_non_inf['method'] == 'STAMP Polar']\n","plt.plot(df_polar['epsilon'], df_polar['mean_accuracy'],\n","         label='STAMP Polar', marker='o', linestyle='-', linewidth=3) # Set linewidth\n","\n","# STAMP Laplace\n","df_laplace = df_agg_non_inf[df_agg_non_inf['method'] == 'STAMP Laplace']\n","plt.plot(df_laplace['epsilon'], df_laplace['mean_accuracy'],\n","         label='STAMP Laplace', marker='o', linestyle='-', linewidth=3) # Set linewidth\n","\n","\n","# GPT-4 Fill + kmack baseline\n","# Calculate baseline directly from the loaded results CSV\n","if 'yelp_gpt4_fill_kmack_results' in dataframes and 'em_privatized' in dataframes['yelp_gpt4_fill_kmack_results'].columns:\n","    baseline_gpt4fill_acc = dataframes['yelp_gpt4_fill_kmack_results']['em_privatized'].mean()\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill)')\n","    print(f\"Baseline (GPT-4 Fill): {baseline_gpt4fill_acc:.3f}\")\n","else:\n","    print(\"⚠️ GPT-4 Fill baseline data not found in dataframes['yelp_gpt4_fill_kmack_results'] or 'em_privatized' column is missing.\")\n","\n","\n","# --- Style ---\n","plt.title(\"Yelp: STAMP— Polar vs Laplace\", fontsize=20)\n","plt.xlabel(r\"Average per-token privacy budget $\\epsilon$\", fontsize=17)\n","plt.ylabel(\"Accuracy (Exact Match)\", fontsize=17)\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend(title='', fontsize=15) # Removed title\n","plt.tick_params(axis='both', which='major', labelsize=15)\n","plt.show()"],"metadata":{"id":"Fjtqe4iWVzvw","executionInfo":{"status":"aborted","timestamp":1763767063303,"user_tz":420,"elapsed":13952,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9e90f8ca","executionInfo":{"status":"aborted","timestamp":1763767063304,"user_tz":420,"elapsed":13952,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"source":["if 'average_scores_yelp_gpt4_fill' in globals():\n","    display(average_scores_yelp_gpt4_fill)\n","else:\n","    print(\"The variable average_scores_yelp_gpt4_fill is not defined.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Aggregate STAMP Polar data ---\n","df_stamp_polar = df_agg_non_inf[df_agg_non_inf['method'] == 'STAMP Polar']\n","\n","# --- Aggregate Uniform Polar data ---\n","# Ensure df_all_results_combined_uniform is available and processed\n","if 'df_all_results_combined_uniform' not in globals():\n","    # Load the combined evaluation results for uniform files from CSV if not already loaded\n","    csv_output_path_uniform = \"Yelp_evaluation_results_uniform_rounds.csv\"\n","    try:\n","        df_all_results_combined_uniform = pd.read_csv(csv_output_path_uniform)\n","        print(f\"Successfully loaded data from {csv_output_path_uniform}\")\n","    except FileNotFoundError:\n","        print(f\"Error: File not found at {csv_output_path_uniform}.\")\n","        df_all_results_combined_uniform = pd.DataFrame() # Create empty dataframe to avoid errors\n","\n","if not df_all_results_combined_uniform.empty:\n","    # Process the 'Yelp_evaluation_results_uniform_rounds' dataframe if not already processed\n","    if 'epsilon' not in df_all_results_combined_uniform.columns or 'method' not in df_all_results_combined_uniform.columns:\n","        df_all_results_combined_uniform['epsilon'] = df_all_results_combined_uniform['dataframe'].apply(\n","            lambda x: float(x.split('_')[-1]) if x.split('_')[-1].replace('.', '', 1).isdigit() else float('nan')\n","        )\n","        df_all_results_combined_uniform['method'] = df_all_results_combined_uniform['dataframe'].apply(\n","            lambda x: 'Uniform Laplace' if 'laplace' in x.lower() else 'Uniform Polar'\n","        )\n","\n","    # Aggregate mean accuracy by epsilon + method for Uniform\n","    df_uniform_agg = (\n","        df_all_results_combined_uniform.groupby(['epsilon', 'method'])\n","        .agg(mean_accuracy=('em_privatized', 'mean'))\n","        .reset_index()\n","        .sort_values('epsilon')\n","    )\n","    df_uniform_polar = df_uniform_agg[df_uniform_agg['method'] == 'Uniform Polar']\n","else:\n","    df_uniform_polar = pd.DataFrame() # Create empty dataframe if uniform data not loaded\n","\n","# --- Plot ---\n","plt.figure(figsize=(8, 5))\n","\n","# STAMP Polar\n","if not df_stamp_polar.empty:\n","    plt.plot(df_stamp_polar['epsilon'], df_stamp_polar['mean_accuracy'],\n","             label='STAMP Polar', marker='o', linestyle='-', linewidth=3)\n","\n","# Uniform Polar\n","if not df_uniform_polar.empty:\n","    plt.plot(df_uniform_polar['epsilon'], df_uniform_polar['mean_accuracy'],\n","             label='Uniform Polar', marker='s', linestyle='--', linewidth=3)\n","\n","# Baselines\n","# Non-Private Yelp 50 baseline (assuming baseline_yelp50_acc is defined)\n","if 'baseline_yelp50_acc' in globals():\n","    plt.axhline(y=baseline_yelp50_acc, color='green', linestyle='-.', linewidth=2,\n","                label='Baseline (Non-Private Yelp 50)')\n","else:\n","     print(\"⚠️ Baseline (Non-Private Yelp 50) not found — please ensure it is calculated.\")\n","\n","# GPT-4 Fill + kmack baseline (assuming baseline_gpt4fill_acc is defined)\n","if 'baseline_gpt4fill_acc' in globals():\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill)')\n","else:\n","    # Calculate baseline directly from the loaded results CSV if not defined\n","    if 'yelp_gpt4_fill_kmack_results' in dataframes and 'em_privatized' in dataframes['yelp_gpt4_fill_kmack_results'].columns:\n","        baseline_gpt4fill_acc = dataframes['yelp_gpt4_fill_kmack_results']['em_privatized'].mean()\n","        plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                    label='Baseline (GPT-4 Fill)')\n","        print(f\"Baseline (GPT-4 Fill): {baseline_gpt4fill_acc:.3f}\")\n","    else:\n","        print(\"⚠️ GPT-4 Fill baseline data not found.\")\n","\n","\n","# --- Style ---\n","plt.title(\"Yelp: Polar— Uniform vs STAMP\", fontsize=20) # Consistent title\n","plt.xlabel(r\"Average per-token privacy budget $\\epsilon$\", fontsize=17)\n","plt.ylabel(\"Accuracy (Exact Match)\", fontsize=17)\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend(title='', fontsize=15) # Removed title\n","plt.tick_params(axis='both', which='major', labelsize=15)\n","plt.show()"],"metadata":{"id":"GLetXkwTniXr","executionInfo":{"status":"aborted","timestamp":1763767063304,"user_tz":420,"elapsed":13951,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ELEpSIzAniaO","executionInfo":{"status":"aborted","timestamp":1763767063309,"user_tz":420,"elapsed":13955,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DlXCGoFfnico","executionInfo":{"status":"aborted","timestamp":1763767063310,"user_tz":420,"elapsed":13955,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z8K5akG1nifJ","executionInfo":{"status":"aborted","timestamp":1763767063310,"user_tz":420,"elapsed":13954,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- load all uniform_Polar and uniform_Laplace datasets ---\n","csv_files_polar = glob.glob(\"/content/yelp_uniform_polar_sweep_avg_epsilon_*.csv\") # Changed to yelp\n","csv_files_laplace = glob.glob(\"/content/yelp_uniform_laplace_sweep_avg_epsilon_*.csv\") # Changed to yelp\n","\n","csv_files = csv_files_polar + csv_files_laplace\n","print(\"Files found by glob:\", csv_files)\n","\n","dataframes = {}\n","\n","for file in csv_files:\n","    df_name = file.replace(\".csv\", \"\")\n","    dataframes[df_name] = pd.read_csv(file)\n","\n","print(\"Number of dataframes loaded:\", len(dataframes))"],"metadata":{"id":"PODdu2GoZ1UH","executionInfo":{"status":"aborted","timestamp":1763767063310,"user_tz":420,"elapsed":13953,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load classifier\n","tokenizer = AutoTokenizer.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"kmack/YELP-Review_Classifier\")\n","\n","num_rounds = 3\n","all_results_uniform = []\n","\n","for round_num in range(num_rounds):\n","    print(f\"--- Starting Round {round_num + 1}/{num_rounds} ---\")\n","    results_list = []\n","\n","    for df_name, df in dataframes.items():  # Uniform Laplace/Polar\n","        print(f\"Processing DataFrame: {df_name}\")\n","\n","        for index, row in df.iterrows():\n","            question = row[\"question\"]\n","            true_answers = [str(row[\"rating\"])]  # Gold label\n","\n","            privatized_context = row.get(\"privatized_context\", \"\")\n","            original_context = row.get(\"original_context\", \"\")\n","\n","            # --- Classify privatized context ---\n","            try:\n","                inputs = tokenizer(privatized_context, return_tensors=\"pt\", truncation=True, padding=True)\n","                with torch.no_grad():\n","                    outputs = model(**inputs)\n","                pred_label = torch.argmax(outputs.logits, dim=1).item()\n","                answer_privatized = str(pred_label)\n","            except Exception as e:\n","                print(f\"Error classifying privatized context row {index}: {e}\")\n","                answer_privatized = \"\"\n","\n","            # Evaluate privatized\n","            f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","            cosine_privatized = calculate_cosine_similarity(answer_privatized, true_answers, model_sentence)\n","\n","            # --- Save results with both contexts ---\n","            results_list.append({\n","                \"dataframe\": df_name,\n","                \"question\": question,\n","                \"true_answers\": true_answers,\n","                \"original_context\": original_context,\n","                \"privatized_context\": privatized_context,\n","                \"answer_privatized\": answer_privatized,\n","                \"f1_privatized\": f1_privatized,\n","                \"em_privatized\": em_privatized,\n","                \"cosine_privatized\": cosine_privatized,\n","            })\n","\n","    # Store round results\n","    df_round_results = pd.DataFrame(results_list)\n","    all_results_uniform.append(df_round_results)\n","\n","print(f\"\\nFinished {num_rounds} rounds of evaluation for uniform datasets.\")\n","\n","# Combine all results\n","df_all_results_combined_uniform = pd.concat(all_results_uniform, ignore_index=True)\n","\n","# Save to CSV\n","csv_output_path_uniform = \"Yelp_evaluation_results_uniform_rounds.csv\"\n","df_all_results_combined_uniform.to_csv(csv_output_path_uniform, index=False)\n","\n","print(f\"All evaluation results for uniform files saved to {csv_output_path_uniform}\")\n"],"metadata":{"id":"c3NwIWs0pczm","executionInfo":{"status":"aborted","timestamp":1763767063321,"user_tz":420,"elapsed":13963,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Aggregate STAMP ---\n","df_all_results_combined_non_inf['epsilon'] = df_all_results_combined_non_inf['dataframe'].apply(\n","    lambda x: float(x.split('_')[-1]) if x.split('_')[-1].replace('.', '', 1).isdigit() else float('nan')\n",")\n","df_all_results_combined_non_inf['method'] = df_all_results_combined_non_inf['dataframe'].apply(\n","    lambda x: 'STAMP Laplace' if 'laplace' in x.lower() else 'STAMP Polar'\n",")\n","df_stamp_agg = (\n","    df_all_results_combined_non_inf.groupby(['epsilon', 'method'])\n","    .agg(mean_accuracy=('em_privatized', 'mean'))\n","    .reset_index()\n",")\n","\n","# --- Aggregate UNIFORM ---\n","df_all_results_combined_uniform['epsilon'] = df_all_results_combined_uniform['dataframe'].apply(\n","    lambda x: float(x.split('_')[-1]) if x.split('_')[-1].replace('.', '', 1).isdigit() else float('nan')\n",")\n","df_all_results_combined_uniform['method'] = df_all_results_combined_uniform['dataframe'].apply(\n","    lambda x: 'Uniform Laplace' if 'laplace' in x.lower() else 'Uniform Polar'\n",")\n","df_uniform_agg = (\n","    df_all_results_combined_uniform.groupby(['epsilon', 'method'])\n","    .agg(mean_accuracy=('em_privatized', 'mean'))\n","    .reset_index()\n",")\n"],"metadata":{"id":"eed2AvMXZ1Yw","executionInfo":{"status":"aborted","timestamp":1763767063321,"user_tz":420,"elapsed":13962,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 7))\n","\n","# STAMP Polar\n","df_stamp_polar = df_stamp_agg[df_stamp_agg['method'] == 'STAMP Polar']\n","plt.plot(df_stamp_polar['epsilon'], df_stamp_polar['mean_accuracy'],\n","         label='STAMP Polar', marker='o', linestyle='-')\n","\n","# Uniform Polar\n","df_uniform_polar = df_uniform_agg[df_uniform_agg['method'] == 'Uniform Polar']\n","plt.plot(df_uniform_polar['epsilon'], df_uniform_polar['mean_accuracy'],\n","         label='Uniform Polar', marker='s', linestyle='--')\n","\n","# Baselines\n","plt.axhline(y=baseline_yelp50_acc, color='green', linestyle='-.', linewidth=2,\n","            label='Baseline (Non-Private Yelp 50)')\n","if 'average_scores_yelp_gpt4_fill' in globals() and 'mean_em_privatized_kmack' in average_scores_yelp_gpt4_fill:\n","    baseline_gpt4fill_acc = average_scores_yelp_gpt4_fill['mean_em_privatized_kmack']\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill + kmack)')\n","\n","plt.title(\"Polar: Uniform vs STAMP\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy (Exact Match)\")\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"n4RShwNrZ1bC","executionInfo":{"status":"aborted","timestamp":1763767063322,"user_tz":420,"elapsed":13962,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 7))\n","\n","# STAMP Polar\n","plt.plot(df_stamp_polar['epsilon'], df_stamp_polar['mean_accuracy'],\n","         label='STAMP Polar', marker='o', linestyle='-')\n","\n","# STAMP Laplace\n","df_stamp_laplace = df_stamp_agg[df_stamp_agg['method'] == 'STAMP Laplace']\n","plt.plot(df_stamp_laplace['epsilon'], df_stamp_laplace['mean_accuracy'],\n","         label='STAMP Laplace', marker='^', linestyle='--')\n","\n","# Baselines\n","plt.axhline(y=baseline_yelp50_acc, color='green', linestyle='-.', linewidth=2,\n","            label='Baseline (Non-Private Yelp 50)')\n","if 'average_scores_yelp_gpt4_fill' in globals() and 'mean_em_privatized_kmack' in average_scores_yelp_gpt4_fill:\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill + kmack)')\n","\n","plt.title(\"STAMP: Polar vs Laplace\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy (Exact Match)\")\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"58pEfb_3Z1ds","executionInfo":{"status":"aborted","timestamp":1763767063322,"user_tz":420,"elapsed":13961,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Step 3: Plot Uniform Polar vs Uniform Laplace ---\n","plt.figure(figsize=(12, 7))\n","\n","# Uniform Polar\n","df_uniform_polar = df_uniform_agg[df_uniform_agg['method'] == 'Uniform Polar']\n","plt.plot(df_uniform_polar['epsilon'], df_uniform_polar['mean_accuracy'],\n","         label='Uniform Polar', marker='o', linestyle='-')\n","\n","# Uniform Laplace\n","df_uniform_laplace = df_uniform_agg[df_uniform_agg['method'] == 'Uniform Laplace']\n","plt.plot(df_uniform_laplace['epsilon'], df_uniform_laplace['mean_accuracy'],\n","         label='Uniform Laplace', marker='^', linestyle='--')\n","\n","# Baselines\n","plt.axhline(y=baseline_yelp50_acc, color='green', linestyle='-.', linewidth=2,\n","            label='Baseline (Non-Private Yelp 50)')\n","if 'average_scores_yelp_gpt4_fill' in globals() and 'mean_em_privatized_kmack' in average_scores_yelp_gpt4_fill:\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill + kmack)')\n","\n","# Style\n","plt.title(\"Uniform: Polar vs Laplace\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy (Exact Match)\")\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"4xGeWxuyTF1w","executionInfo":{"status":"aborted","timestamp":1763767063322,"user_tz":420,"elapsed":13960,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(14, 8))\n","\n","# --- STAMP ---\n","df_stamp_polar = df_stamp_agg[df_stamp_agg['method'] == 'STAMP Polar']\n","plt.plot(df_stamp_polar['epsilon'], df_stamp_polar['mean_accuracy'],\n","         label='STAMP Polar', marker='o', linestyle='-')\n","\n","df_stamp_laplace = df_stamp_agg[df_stamp_agg['method'] == 'STAMP Laplace']\n","plt.plot(df_stamp_laplace['epsilon'], df_stamp_laplace['mean_accuracy'],\n","         label='STAMP Laplace', marker='^', linestyle='--')\n","\n","# --- UNIFORM ---\n","df_uniform_polar = df_uniform_agg[df_uniform_agg['method'] == 'Uniform Polar']\n","plt.plot(df_uniform_polar['epsilon'], df_uniform_polar['mean_accuracy'],\n","         label='Uniform Polar', marker='s', linestyle='-.')\n","\n","df_uniform_laplace = df_uniform_agg[df_uniform_agg['method'] == 'Uniform Laplace']\n","plt.plot(df_uniform_laplace['epsilon'], df_uniform_laplace['mean_accuracy'],\n","         label='Uniform Laplace', marker='d', linestyle=':')\n","\n","# --- INF ---\n","df_inf_results['epsilon'] = df_inf_results['dataframe'].apply(\n","    lambda x: float(x.split('_')[-1].replace('.csv','')) if 'inf' not in x.lower() else float('inf')\n",")\n","df_inf_results['method'] = df_inf_results['dataframe'].apply(\n","    lambda x: 'Inf Laplace' if 'laplace' in x.lower() else 'Inf Polar'\n",")\n","df_inf_agg = (\n","    df_inf_results.groupby(['epsilon','method'])\n","    .agg(mean_accuracy=('em_privatized','mean'))\n","    .reset_index()\n",")\n","\n","df_inf_polar = df_inf_agg[df_inf_agg['method'] == 'Inf Polar']\n","plt.plot(df_inf_polar['epsilon'], df_inf_polar['mean_accuracy'],\n","         label='Inf Polar', marker='x', linestyle='-')\n","\n","df_inf_laplace = df_inf_agg[df_inf_agg['method'] == 'Inf Laplace']\n","plt.plot(df_inf_laplace['epsilon'], df_inf_laplace['mean_accuracy'],\n","         label='Inf Laplace', marker='x', linestyle='--')\n","\n","# --- Baselines ---\n","plt.axhline(y=baseline_yelp50_acc, color='green', linestyle='-.', linewidth=2,\n","            label='Baseline (Non-Private Yelp 50)')\n","if 'average_scores_yelp_gpt4_fill' in globals() and 'mean_em_privatized_kmack' in average_scores_yelp_gpt4_fill:\n","    plt.axhline(y=baseline_gpt4fill_acc, color='red', linestyle=':', linewidth=2,\n","                label='Baseline (GPT-4 Fill + kmack)')\n","\n","# --- Style ---\n","plt.title(\"Comparison of All Mechanisms (Polar vs Laplace, STAMP vs Uniform vs Inf)\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy (Exact Match)\")\n","plt.ylim(0, 1.1)\n","plt.grid(True)\n","plt.legend(title=\"Mechanism\", bbox_to_anchor=(1.05, 1), loc='upper left')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"sTbxCx1yTF7m","executionInfo":{"status":"aborted","timestamp":1763767063323,"user_tz":420,"elapsed":13960,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U9cNbPBpTF-G","executionInfo":{"status":"aborted","timestamp":1763767063323,"user_tz":420,"elapsed":13959,"user":{"displayName":"Feng Wei Tian","userId":"15545888329392400707"}}},"execution_count":null,"outputs":[]}]}