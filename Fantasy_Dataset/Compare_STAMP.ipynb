{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPy7jh5j8W58QfX4cR/aBpW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"opy49YOY1Pqy"},"outputs":[],"source":["# Library\n","\n","import torch\n","import math\n","import re\n","import numpy as np\n","import pandas as pd\n","from torch.distributions import Laplace\n","import ast, time\n","from tqdm import tqdm\n","import pandas as pd\n","\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoModelForCausalLM\n","from transformers import GPT2LMHeadModel\n","\n","from datasets import load_dataset\n","from sentence_transformers import SentenceTransformer, util\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from scipy.stats import vonmises_fisher\n","import torch.nn.functional as F\n","\n","from typing import Dict, List, Optional\n","\n","from openai import OpenAI\n","import glob\n","import os\n","from collections import Counter\n","\n","from sentence_transformers import SentenceTransformer\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","metadata":{"id":"f9fffe1f"},"source":["client = OpenAI(api_key=\"Your_API_Key\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Load tokenizer and GPT-2 model ---\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\", output_hidden_states=True)\n","embedding_table = model.get_input_embeddings().weight.detach()\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","model.eval()\n","\n","# Base tokenizer pad fix (optional)\n","if getattr(tokenizer, \"pad_token_id\", None) is None and getattr(tokenizer, \"eos_token\", None) is not None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# Load a light GPT-2 model\n","gpt2_tok = AutoTokenizer.from_pretrained(\"distilgpt2\")\n","if gpt2_tok.pad_token is None:\n","    gpt2_tok.pad_token = gpt2_tok.eos_token\n","gpt2_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(\n","    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",").eval()\n","\n","# --- Extract embedding table ---\n","# Normalize embedding table for search\n","norm_embedding_table = torch.nn.functional.normalize(embedding_table, dim=1)"],"metadata":{"id":"YZecP5w2lVxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3356ff3a"},"source":["# Get the answers\n","\n","def normalize_answer(s):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        return re.sub(r'[^\\w\\s]', '', text)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","def get_tokens(s):\n","    if not s: return []\n","    return normalize_answer(s).split()\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = get_tokens(prediction)\n","    truth_tokens = get_tokens(truth)\n","\n","    # if either is empty, return 1 if both are empty, 0 otherwise\n","    if not pred_tokens and not truth_tokens:\n","        return 1.0\n","    if not pred_tokens or not truth_tokens:\n","        return 0.0\n","\n","    common_tokens = Counter(pred_tokens) & Counter(truth_tokens)\n","    num_common = sum(common_tokens.values())\n","\n","    if num_common == 0:\n","        return 0.0\n","\n","    precision = num_common / len(pred_tokens)\n","    recall = num_common / len(truth_tokens)\n","\n","    return (2 * precision * recall) / (precision + recall)\n","\n","def evaluate_answer(predicted_answer: str, true_answers: list[str]):\n","    \"\"\"\n","    Evaluates a predicted answer against a list of true answers using F1 score and exact match.\n","\n","    Args:\n","        predicted_answer: The generated answer string.\n","        true_answers: A list of true answer strings.\n","\n","    Returns:\n","        A tuple containing:\n","            - The maximum F1 score achieved against any of the true answers.\n","            - A boolean indicating whether an exact match was found against any of the true answers.\n","    \"\"\"\n","    max_f1 = 0.0\n","    exact_match = False\n","\n","    normalized_prediction = normalize_answer(predicted_answer)\n","\n","    for true_answer in true_answers:\n","        normalized_true = normalize_answer(true_answer)\n","\n","        # Exact Match\n","        if normalized_prediction == normalized_true:\n","            exact_match = True\n","\n","        # F1 Score\n","        f1 = compute_f1(predicted_answer, true_answer)\n","        max_f1 = max(max_f1, f1)\n","\n","    return max_f1, exact_match\n","\n","\n","def calculate_cosine_similarity(prediction: str, truths: list[str], model) -> float:\n","    \"\"\"\n","    Calculates the cosine similarity between the prediction and each true answer\n","    using Sentence-BERT embeddings and returns the maximum similarity.\n","    \"\"\"\n","    if not prediction or not truths:\n","        return 0.0\n","\n","    # Encode the prediction\n","    prediction_embedding = model.encode(prediction, convert_to_tensor=True)\n","\n","    max_similarity = 0.0\n","    for truth in truths:\n","        if not truth:\n","            continue\n","        # Encode the true answer\n","        truth_embedding = model.encode(truth, convert_to_tensor=True)\n","\n","        # Calculate cosine similarity\n","        similarity = util.pytorch_cos_sim(prediction_embedding, truth_embedding).item()\n","        max_similarity = max(max_similarity, similarity)\n","\n","    return max_similarity\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sOYdjIRM06O9"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f92cdee9"},"source":["# --- Load all INF Polar and INF Laplace datasets ---\n","csv_files_polar_inf = glob.glob(\"/content/squad_inf_polar_sweep_avg_epsilon_*.csv\")\n","csv_files_laplace_inf = glob.glob(\"/content/squad_inf_laplace_sweep_avg_epsilon_*.csv\")\n","\n","csv_files = csv_files_polar_inf + csv_files_laplace_inf\n","print(\"Files found by glob:\", csv_files)\n","\n","dataframes = {}\n","\n","for file in csv_files:\n","    df_name = file.replace(\".csv\", \"\")\n","    dataframes[df_name] = pd.read_csv(file)\n","\n","print(\"Number of dataframes loaded:\", len(dataframes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-3JY7x-iVbPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b620167e"},"source":["# Initialize Sentence Transformer model\n","model_sentence = SentenceTransformer('all-MiniLM-L6-v2')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"07c479d9","collapsed":true},"source":["num_rounds = 3\n","all_results = []\n","\n","for round_num in range(num_rounds):\n","    print(f\"--- Starting Round {round_num + 1}/{num_rounds} ---\")\n","    results_list = []\n","\n","    for df_name, df in dataframes.items():\n","        print(f\"Processing DataFrame: {df_name}\")\n","        for index, row in df.iterrows():\n","            question = row[\"question\"]\n","            true_answers = eval(row[\"answers\"]) # Assuming 'answers' is stored as a string representation of a list\n","            privatized_context = row[\"privatized_context\"]\n","            repaired_context = row[\"repaired_context\"]\n","\n","            # Generate answer for privatized context\n","            try:\n","                response_privatized = client.chat.completions.create(\n","                    model=\"gpt-4o-mini\",\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                        {\"role\": \"user\", \"content\": f\"Context: {privatized_context}\\nQuestion: {question}\"}\n","                    ],\n","                    temperature=0.2,\n","                    max_tokens=5, # Limit response to one word, but just in case\n","                )\n","                answer_privatized = response_privatized.choices[0].message.content.strip()\n","            except Exception as e:\n","                print(f\"Error generating answer for privatized context: {e}\")\n","                answer_privatized = \"\"\n","\n","\n","            # Generate answer for repaired context\n","            try:\n","                response_repaired = client.chat.completions.create(\n","                    model=\"gpt-4o-mini\",\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                        {\"role\": \"user\", \"content\": f\"Context: {repaired_context}\\nQuestion: {question}\"}\n","                    ],\n","                    temperature=0.2,\n","                    max_tokens=5, # Limit response to one word, but just in case\n","                )\n","                answer_repaired = response_repaired.choices[0].message.content.strip()\n","            except Exception as e:\n","                print(f\"Error generating answer for repaired context: {e}\")\n","                answer_repaired = \"\"\n","\n","\n","            # Evaluate answers (F1 and EM already calculated)\n","            f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","            f1_repaired, em_repaired = evaluate_answer(answer_repaired, true_answers)\n","\n","            # Calculate Cosine Similarity\n","\n","            cosine_privatized = calculate_cosine_similarity(answer_privatized, true_answers, model_sentence)\n","            cosine_repaired = calculate_cosine_similarity(answer_repaired, true_answers, model_sentence)\n","\n","            results_list.append({\n","                \"dataframe\": df_name,\n","                \"question\": question,\n","                \"true_answers\": true_answers,\n","                \"answer_privatized\": answer_privatized,\n","                \"f1_privatized\": f1_privatized,\n","                \"em_privatized\": em_privatized,\n","                \"cosine_privatized\": cosine_privatized,\n","                \"answer_repaired\": answer_repaired,\n","                \"f1_repaired\": f1_repaired,\n","                \"em_repaired\": em_repaired,\n","                \"cosine_repaired\": cosine_repaired,\n","            })\n","    # Convert results list to DataFrame for the current round\n","    df_round_results = pd.DataFrame(results_list)\n","    all_results.append(df_round_results)\n","\n","# The list 'all_results' now contains a DataFrame for each round\n","print(f\"\\nFinished {num_rounds} rounds of evaluation.\")\n","# You can now proceed to aggregate across the dataframes in all_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Combine all Fantasy SQuAD evaluation results and save to CSV ---\n","\n","# Concatenate all round results into one DataFrame\n","df_all_results_combined_squad = pd.concat(all_results, ignore_index=True)\n","\n","# Define output path\n","csv_output_path_squad = \"FantasySQuAD_evaluation_results_inf_rounds.csv\"\n","\n","# Save to CSV\n","df_all_results_combined_squad.to_csv(csv_output_path_squad, index=False)\n","\n","print(f\"\\n‚úÖ All Fantasy SQuAD evaluation results saved to {csv_output_path_squad}\")\n"],"metadata":{"id":"LlixS32lwJxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Load the Fantasy SQuAD GPT-4 Fill dataset ---\n","file_path_squad_gpt4_fill = \"/content/FantasySQuAD_gpt4_fill_results_with_original.csv\"  # adjust if filename differs\n","\n","try:\n","    df_squad_gpt4_fill = pd.read_csv(file_path_squad_gpt4_fill)\n","    print(f\"‚úÖ Loaded dataset: {file_path_squad_gpt4_fill}\")\n","    display(df_squad_gpt4_fill.head())\n","except FileNotFoundError:\n","    print(f\"‚ùå Error: File not found at {file_path_squad_gpt4_fill}\")\n","    df_squad_gpt4_fill = None\n"],"metadata":{"id":"_b41qVLIVuz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"23d172a1"},"source":["\n","if df_squad_gpt4_fill is not None:\n","    results_list = []\n","\n","    for idx, row in tqdm(df_squad_gpt4_fill.iterrows(), total=len(df_squad_gpt4_fill)):\n","        question = row.get(\"question\", \"\")\n","        true_answers = (\n","            ast.literal_eval(row[\"true_answers\"])\n","            if isinstance(row[\"true_answers\"], str)\n","            else row[\"true_answers\"]\n","        )\n","\n","        original_context = row.get(\"original_context\", \"\")\n","        privatized_context = row.get(\"privatized_context\", \"\")\n","        repaired_context = row.get(\"repaired_context\", \"\")\n","\n","        # --- GPT on original ---\n","        try:\n","            resp_orig = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"Answer the question based on the context. Limit your answer to one short span or word.\"},\n","                    {\"role\": \"user\", \"content\": f\"Context: {original_context}\\nQuestion: {question}\"}\n","                ],\n","                temperature=0.2,\n","                max_tokens=15,\n","            )\n","            ans_orig = resp_orig.choices[0].message.content.strip()\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Error on original context row {idx}: {e}\")\n","            ans_orig = \"\"\n","\n","        # --- GPT on privatized (masked) context ---\n","        try:\n","            resp_priv = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"Answer the question based on the context. Limit your answer to one short span or word.\"},\n","                    {\"role\": \"user\", \"content\": f\"Context: {privatized_context}\\nQuestion: {question}\"}\n","                ],\n","                temperature=0.2,\n","                max_tokens=15,\n","            )\n","            ans_priv = resp_priv.choices[0].message.content.strip()\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Error on privatized context row {idx}: {e}\")\n","            ans_priv = \"\"\n","\n","        # --- GPT on repaired (filled) context ---\n","        try:\n","            resp_rep = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"Answer the question based on the context. Limit your answer to one short span or word.\"},\n","                    {\"role\": \"user\", \"content\": f\"Context: {repaired_context}\\nQuestion: {question}\"}\n","                ],\n","                temperature=0.2,\n","                max_tokens=15,\n","            )\n","            ans_rep = resp_rep.choices[0].message.content.strip()\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Error on repaired context row {idx}: {e}\")\n","            ans_rep = \"\"\n","\n","        # --- Evaluate ---\n","        f1_orig, em_orig = evaluate_answer(ans_orig, true_answers)\n","        f1_priv, em_priv = evaluate_answer(ans_priv, true_answers)\n","        f1_rep, em_rep = evaluate_answer(ans_rep, true_answers)\n","\n","        cos_orig = calculate_cosine_similarity(ans_orig, true_answers, model_sentence)\n","        cos_priv = calculate_cosine_similarity(ans_priv, true_answers, model_sentence)\n","        cos_rep = calculate_cosine_similarity(ans_rep, true_answers, model_sentence)\n","\n","        results_list.append({\n","            \"question\": question,\n","            \"true_answers\": true_answers,\n","            \"original_context\": original_context,\n","            \"privatized_context\": privatized_context,\n","            \"repaired_context\": repaired_context,\n","            \"answer_original\": ans_orig,\n","            \"answer_privatized\": ans_priv,\n","            \"answer_repaired\": ans_rep,\n","            \"f1_original\": f1_orig,\n","            \"em_original\": em_orig,\n","            \"cosine_original\": cos_orig,\n","            \"f1_privatized\": f1_priv,\n","            \"em_privatized\": em_priv,\n","            \"cosine_privatized\": cos_priv,\n","            \"f1_repaired\": f1_rep,\n","            \"em_repaired\": em_rep,\n","            \"cosine_repaired\": cos_rep,\n","        })\n","\n","    # --- Combine & save ---\n","    df_squad_gpt4_fill_results = pd.DataFrame(results_list)\n","    csv_output_path = \"FantasySQuAD_gpt4_fill_results_with_original.csv\"\n","    df_squad_gpt4_fill_results.to_csv(csv_output_path, index=False)\n","\n","    print(f\"\\n‚úÖ Fantasy SQuAD GPT-4 Fill results (with original context) saved to: {csv_output_path}\")\n","\n","    # --- Summary ---\n","    avg_scores = {\n","        \"mean_f1_original\": df_squad_gpt4_fill_results[\"f1_original\"].mean(),\n","        \"mean_em_original\": df_squad_gpt4_fill_results[\"em_original\"].mean(),\n","        \"mean_cosine_original\": df_squad_gpt4_fill_results[\"cosine_original\"].mean(),\n","        \"mean_f1_privatized\": df_squad_gpt4_fill_results[\"f1_privatized\"].mean(),\n","        \"mean_em_privatized\": df_squad_gpt4_fill_results[\"em_privatized\"].mean(),\n","        \"mean_cosine_privatized\": df_squad_gpt4_fill_results[\"cosine_privatized\"].mean(),\n","        \"mean_f1_repaired\": df_squad_gpt4_fill_results[\"f1_repaired\"].mean(),\n","        \"mean_em_repaired\": df_squad_gpt4_fill_results[\"em_repaired\"].mean(),\n","        \"mean_cosine_repaired\": df_squad_gpt4_fill_results[\"cosine_repaired\"].mean(),\n","    }\n","\n","    display(pd.DataFrame([avg_scores]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UMCLM8Qe1_D7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Load Files ===\n","inf_results_path = \"/content/FantasySQuAD_evaluation_results_inf_rounds.csv\"\n","baseline_path = \"/content/FantasySQuAD_gpt4_fill_results_with_original.csv\"\n","\n","df_inf = pd.read_csv(inf_results_path)\n","df_base = pd.read_csv(baseline_path)\n","print(f\"‚úÖ Loaded {len(df_inf)} INF results and {len(df_base)} baseline rows.\")\n","\n","# === Extract epsilon/method ===\n","if \"dataframe\" in df_inf.columns:\n","    df_inf[\"epsilon\"] = df_inf[\"dataframe\"].apply(\n","        lambda x: float(re.search(r\"epsilon_([\\d.]+)\", str(x)).group(1))\n","        if isinstance(x, str) and \"epsilon_\" in x else None)\n","    df_inf[\"method\"] = df_inf[\"dataframe\"].apply(\n","        lambda x: \"Inf Laplace\" if \"laplace\" in str(x).lower()\n","        else \"Inf Polar\" if \"polar\" in str(x).lower()\n","        else \"Unknown\")\n","\n","# === Compute GPT-Judged Correctness (INF results) ===\n","df_inf[\"gpt_judged_correct\"] = False\n","for i, row in tqdm(df_inf.iterrows(), total=len(df_inf)):\n","    question = row.get(\"question\", \"\")\n","    pred = row.get(\"answer_privatized\", \"\")\n","    try:\n","        gold = ast.literal_eval(row[\"true_answers\"]) if isinstance(row[\"true_answers\"], str) else row[\"true_answers\"]\n","    except Exception:\n","        gold = [str(row.get(\"true_answers\", \"\"))]\n","    df_inf.loc[i, \"gpt_judged_correct\"] = gpt_judge(pred, gold, question)\n","    time.sleep(0.25)\n","\n","# === Aggregate Mean Metrics ===\n","df_inf_clean = df_inf.dropna(subset=[\"em_privatized\", \"f1_privatized\", \"cosine_privatized\"])\n","df_agg = (\n","    df_inf_clean.groupby([\"epsilon\", \"method\"])\n","    .agg(\n","        mean_em=(\"em_privatized\", \"mean\"),\n","        mean_f1=(\"f1_privatized\", \"mean\"),\n","        mean_cosine=(\"cosine_privatized\", \"mean\"),\n","        mean_gpt_accuracy=(\"gpt_judged_correct\", \"mean\"),\n","    ).reset_index()\n",")\n","\n","# === Compute Baseline Metrics ===\n","baseline_em = df_base.filter(like=\"em\").mean().mean()\n","baseline_f1 = df_base.filter(like=\"f1\").mean().mean()\n","baseline_cos = df_base.filter(like=\"cosine\").mean().mean()\n","print(f\"‚úÖ Baselines ‚Äî EM: {baseline_em:.4f}, F1: {baseline_f1:.4f}, Cosine: {baseline_cos:.4f}\")\n","\n","# === Save Updated File ===\n","df_inf.to_csv(\"/content/FantasySQuAD_with_gpt_judged_accuracy.csv\", index=False)\n","print(\"üíæ Saved enhanced FantasySQuAD results with GPT-judged accuracy.\")\n"],"metadata":{"id":"PfMtCB8yyGhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LqWXw-P40Gcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4acc517e"},"source":["# Compute GPT-Judged Correctness (Baseline results)\n","df_base[\"gpt_judged_correct\"] = False\n","for i, row in tqdm(df_base.iterrows(), total=len(df_base)):\n","    question = row.get(\"question\", \"\")\n","    pred = row.get(\"answer_original\", \"\") # Use answer_original for baseline\n","    try:\n","        gold = ast.literal_eval(row[\"true_answers\"]) if isinstance(row[\"true_answers\"], str) else row[\"true_answers\"]\n","    except Exception:\n","        gold = [str(row.get(\"true_answers\", \"\"))]\n","    df_base.loc[i, \"gpt_judged_correct\"] = gpt_judge(pred, gold, question)\n","    time.sleep(0.25)\n","\n","# Calculate and display the mean GPT-judged accuracy for the baseline\n","baseline_gpt_accuracy = df_base[\"gpt_judged_correct\"].mean()\n","print(f\"‚úÖ Baseline GPT-Judged Accuracy: {baseline_gpt_accuracy:.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X-ppxUv90GfK"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ee2e1f0"},"source":["# Save the updated baseline DataFrame with GPT-judged accuracy\n","output_baseline_path = \"FantasySQuAD_gpt4_fill_results_with_original_and_gpt_accuracy.csv\"\n","df_base.to_csv(output_baseline_path, index=False)\n","print(f\"‚úÖ Updated baseline results (with GPT-judged accuracy) saved to: {output_baseline_path}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F4f8vGb0Cyg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Helper Plot Function ===\n","def plot_metric(col, ylabel, baseline, title):\n","    plt.figure(figsize=(12,7))\n","    for method in df_agg[\"method\"].unique():\n","        sub = df_agg[df_agg[\"method\"] == method]\n","        plt.plot(sub[\"epsilon\"], sub[col], marker=\"o\", linestyle=\"--\", label=method)\n","    if baseline is not None:\n","        plt.axhline(y=baseline, color=\"red\", linestyle=\":\", linewidth=2, label=\"Baseline (GPT-4 Fill)\")\n","    plt.title(f\"Fantasy SQuAD ‚Äî {title} vs Epsilon\")\n","    plt.xlabel(\"Epsilon\")\n","    plt.ylabel(ylabel)\n","    plt.ylim(0, 1.05)\n","    plt.grid(True)\n","    plt.legend(title=\"Mechanism\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","# === Plot All Metrics ===\n","plot_metric(\"mean_em\", \"Exact Match\", baseline_em, \"Exact Match (EM)\")\n","plot_metric(\"mean_f1\", \"F1 Score\", baseline_f1, \"F1 Score\")\n","plot_metric(\"mean_cosine\", \"Cosine Similarity\", baseline_cos, \"Cosine Similarity\")\n","plot_metric(\"mean_gpt_accuracy\", \"GPT-Judged Accuracy\", baseline_gpt_accuracy, \"GPT-Judged Accuracy\")"],"metadata":{"collapsed":true,"id":"hYaiuwG2CyjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"df9f3117","collapsed":true},"source":["\n","# --- Load Fantasy SQuAD INF results ---\n","inf_results_path = \"/content/FantasySQuAD_evaluation_results_inf_rounds.csv\"\n","df_all_results_combined = pd.read_csv(inf_results_path)\n","print(f\"‚úÖ Loaded {len(df_all_results_combined)} total rows from INF results.\")\n","\n","# --- Extract epsilon values ---\n","df_all_results_combined['epsilon'] = df_all_results_combined['dataframe'].apply(\n","    lambda x: float(re.search(r\"epsilon_([\\d.]+)\", str(x)).group(1))\n","    if isinstance(x, str) and \"epsilon_\" in x else np.nan\n",")\n","\n","# --- Filter and classify methods ---\n","df_inf_results = df_all_results_combined[\n","    df_all_results_combined['dataframe'].str.contains('_inf_', case=False, na=False)\n","].copy()\n","df_inf_results['method'] = df_inf_results['dataframe'].apply(\n","    lambda x: 'Inf Laplace' if 'laplace' in str(x).lower() else 'Inf Polar'\n",")\n","\n","# --- Aggregate metrics ---\n","df_aggregated_inf = (\n","    df_inf_results.groupby(['epsilon', 'method'])\n","    .agg(\n","        mean_f1_privatized=('f1_privatized', 'mean'),\n","        std_f1_privatized=('f1_privatized', 'std'),\n","        mean_f1_repaired=('f1_repaired', 'mean'),\n","        std_f1_repaired=('f1_repaired', 'std'),\n","        mean_cosine_privatized=('cosine_privatized', 'mean'),\n","        std_cosine_privatized=('cosine_privatized', 'std'),\n","        mean_cosine_repaired=('cosine_repaired', 'mean'),\n","        std_cosine_repaired=('cosine_repaired', 'std'),\n","    )\n","    .reset_index()\n","    .sort_values('epsilon')\n",")\n","print(\"‚úÖ Aggregated results ready for plotting.\")\n","\n","# --- Plot: Cosine Similarity (Privatized Context) ---\n","plt.figure(figsize=(12, 7))\n","\n","for method, style in [(\"Inf Laplace\", \"-\"), (\"Inf Polar\", \"--\")]:\n","    df_method = df_aggregated_inf[df_aggregated_inf['method'] == method]\n","    y = df_method['mean_cosine_privatized']\n","    yerr = df_method['std_cosine_privatized']\n","\n","    # Cap error bars within [0, 1]\n","    upper_error = np.minimum(y + yerr, 1) - y\n","    lower_error = y - np.maximum(y - yerr, 0)\n","\n","    plt.errorbar(\n","        df_method['epsilon'], y,\n","        yerr=[lower_error, upper_error],\n","        label=f\"{method} (Privatized Context)\",\n","        marker='o', capsize=5, linestyle=style\n","    )\n","\n","# --- Add GPT-4 Mask & Fill Baseline if available ---\n","try:\n","    df_mask_fill_results = pd.read_csv(\"/content/FantasySQuAD_gpt4_fill_results_with_original.csv\")\n","    baseline_cosine = df_mask_fill_results['cosine_gpt4_fill'].mean() if 'cosine_gpt4_fill' in df_mask_fill_results.columns \\\n","        else df_mask_fill_results.filter(like=\"cosine\").mean().mean()\n","    plt.axhline(y=baseline_cosine, color='red', linestyle=':', linewidth=2,\n","                label=f\"GPT-4 Mask & Fill Baseline ({baseline_cosine:.3f})\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not load GPT-4 Fill baseline: {e}\")\n","\n","# --- Styling ---\n","plt.title(\"Fantasy SQuAD ‚Äî Cosine Similarity (Privatized Context) vs Epsilon for INF Mechanisms\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Average Cosine Similarity\")\n","plt.ylim(0, 1.05)\n","plt.grid(True)\n","plt.legend(title=\"Method\", fontsize=10)\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WRr7W3QlCyl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B7h4LhLB-kS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ehUZ0nA4-kQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49024a44"},"source":["# Extract tau values from the 'dataframe' column (if not already done in df_all_results_combined)\n","if 'tau' not in df_all_results_combined.columns:\n","    df_all_results_combined['tau'] = df_all_results_combined['dataframe'].apply(lambda x: float(x.split('_')[-1]))\n","\n","# Create the plot for F1 scores with shaded standard deviation\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(data=df_all_results_combined, x='tau', y='f1_privatized', label='Privatized Context', marker='o', errorbar='sd')\n","sns.lineplot(data=df_all_results_combined, x='tau', y='f1_repaired', label='Repaired Context', marker='o', errorbar='sd')\n","\n","plt.title('Average F1 Score vs. Importance Threshold')\n","plt.xlabel('Importance Threshold')\n","plt.ylabel('Average F1 Score')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ef18a304"},"source":["# Extract tau values from the 'dataframe' column (if not already done in df_all_results_combined)\n","if 'tau' not in df_all_results_combined.columns:\n","    df_all_results_combined['tau'] = df_all_results_combined['dataframe'].apply(lambda x: float(x.split('_')[-1]))\n","\n","# Create the plot for Cosine Similarity with shaded standard deviation\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(data=df_all_results_combined, x='tau', y='cosine_privatized', label='Privatized Context', marker='o', errorbar='sd')\n","sns.lineplot(data=df_all_results_combined, x='tau', y='cosine_repaired', label='Repaired Context', marker='o', errorbar='sd')\n","\n","plt.title('Average Cosine Similarity vs. Importance Threshold')\n","plt.xlabel('Importance Threshold')\n","plt.ylabel('Average Cosine Similarity Score')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1a502a0"},"source":["# Extract tau values from the 'dataframe' column (if not already done in df_all_results_combined)\n","if 'tau' not in df_all_results_combined.columns:\n","    df_all_results_combined['tau'] = df_all_results_combined['dataframe'].apply(lambda x: float(x.split('_')[-1]))\n","\n","# Create the plot for F1 scores with confidence intervals\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(data=df_all_results_combined, x='tau', y='f1_privatized', label='Privatized Context', marker='o', errorbar=('ci', 95))\n","sns.lineplot(data=df_all_results_combined, x='tau', y='f1_repaired', label='Repaired Context', marker='o', errorbar=('ci', 95))\n","\n","plt.title('Average F1 Score vs. Importance Threshold (95% Confidence Interval)')\n","plt.xlabel('Importance Threshold')\n","plt.ylabel('Average F1 Score')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c545e017"},"source":["# Extract tau values from the 'dataframe' column (if not already done in df_all_results_combined)\n","if 'tau' not in df_all_results_combined.columns:\n","    df_all_results_combined['tau'] = df_all_results_combined['dataframe'].apply(lambda x: float(x.split('_')[-1]))\n","\n","# Create the plot for Cosine Similarity with confidence intervals\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(data=df_all_results_combined, x='tau', y='cosine_privatized', label='Privatized Context', marker='o', errorbar=('ci', 95))\n","sns.lineplot(data=df_all_results_combined, x='tau', y='cosine_repaired', label='Repaired Context', marker='o', errorbar=('ci', 95))\n","\n","plt.title('Average Cosine Similarity vs. Importance Threshold (95% Confidence Interval)')\n","plt.xlabel('Importance Threshold')\n","plt.ylabel('Average Cosine Similarity Score')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HjxVlyKy-kOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"915e5481"},"source":["df_mask_fill = pd.read_csv('/content/squad_gpt4_mask_fill.csv')\n","display(df_mask_fill.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ac8fb564"},"source":["results_list_mask_fill = []\n","\n","for index, row in df_mask_fill.iterrows():\n","    question = row[\"question\"]\n","    # Safely evaluate the string representation of the list of answers\n","    try:\n","        true_answers = eval(row[\"answers\"])\n","        if not isinstance(true_answers, list):\n","             true_answers = [true_answers] # Ensure it's a list even if eval returns a single item\n","    except Exception as e:\n","        print(f\"Error evaluating answers for row {index}: {e}\")\n","        true_answers = []\n","\n","    privatized_context = row[\"privatized_context\"]\n","    repaired_context = row[\"repaired_context\"]\n","\n","    # Generate answer for privatized context\n","    try:\n","        response_privatized = client.chat.completions.create(\n","            model=\"gpt-4o-mini\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                {\"role\": \"user\", \"content\": f\"Context: {privatized_context}\\nQuestion: {question}\"}\n","            ],\n","            temperature=0.2,\n","            max_tokens=5,\n","        )\n","        answer_privatized = response_privatized.choices[0].message.content.strip()\n","    except Exception as e:\n","        print(f\"Error generating answer for privatized context in row {index}: {e}\")\n","        answer_privatized = \"\"\n","\n","    # Generate answer for repaired context\n","    try:\n","        response_repaired = client.chat.completions.create(\n","            model=\"gpt-4o-mini\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                {\"role\": \"user\", \"content\": f\"Context: {repaired_context}\\nQuestion: {question}\"}\n","            ],\n","            temperature=0.2,\n","            max_tokens=5,\n","        )\n","        answer_repaired = response_repaired.choices[0].message.content.strip()\n","    except Exception as e:\n","        print(f\"Error generating answer for repaired context in row {index}: {e}\")\n","        answer_repaired = \"\"\n","\n","    # Evaluate answers\n","    f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","    f1_repaired, em_repaired = evaluate_answer(answer_repaired, true_answers)\n","\n","    # Calculate Cosine Similarity\n","    cosine_privatized = calculate_cosine_similarity(answer_privatized, true_answers, model_sentence)\n","    cosine_repaired = calculate_cosine_similarity(answer_repaired, true_answers, model_sentence)\n","\n","    results_list_mask_fill.append({\n","        \"question\": question,\n","        \"true_answers\": true_answers,\n","        \"answer_privatized\": answer_privatized,\n","        \"f1_privatized\": f1_privatized,\n","        \"em_privatized\": em_privatized,\n","        \"cosine_privatized\": cosine_privatized,\n","        \"answer_repaired\": answer_repaired,\n","        \"f1_repaired\": f1_repaired,\n","        \"em_repaired\": em_repaired,\n","        \"cosine_repaired\": cosine_repaired,\n","    })\n","\n","# Convert results list to DataFrame\n","df_mask_fill_results = pd.DataFrame(results_list_mask_fill)\n","display(df_mask_fill_results.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09ba29c8"},"source":["average_scores = {\n","    'mean_f1_privatized': df_mask_fill_results['f1_privatized'].mean(),\n","    'mean_em_privatized': df_mask_fill_results['em_privatized'].mean(),\n","    'mean_cosine_privatized': df_mask_fill_results['cosine_privatized'].mean(),\n","    'mean_f1_repaired': df_mask_fill_results['f1_repaired'].mean(),\n","    'mean_em_repaired': df_mask_fill_results['em_repaired'].mean(),\n","    'mean_cosine_repaired': df_mask_fill_results['cosine_repaired'].mean()\n","}\n","\n","# Convert to DataFrame for display\n","df_average_scores = pd.DataFrame([average_scores])\n","display(df_average_scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2fcb3f2"},"source":["# Save the results DataFrame to a CSV file\n","csv_output_path_mask_fill = \"squad_gpt4_mask_fill_results.csv\"\n","df_mask_fill_results.to_csv(csv_output_path_mask_fill, index=False)\n","\n","print(f\"Evaluation results for mask fill saved to {csv_output_path_mask_fill}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42b5de0b"},"source":["# --- load all UNIFORM_Polar and UNIFORM_Laplace datasets ---\n","csv_files_uniform_polar = glob.glob(\"/content/squad_uniform_polar_sweep_avg_epsilon_*.csv\")\n","csv_files_uniform_laplace = glob.glob(\"/content/squad_uniform_laplace_sweep_avg_epsilon_*.csv\")\n","\n","csv_files_uniform = csv_files_uniform_polar + csv_files_uniform_laplace\n","print(\"Files found by glob:\", csv_files_uniform)\n","\n","dataframes_uniform = {}\n","\n","for file in csv_files_uniform:\n","    df_name = file.replace(\".csv\", \"\")\n","    dataframes_uniform[df_name] = pd.read_csv(file)\n","\n","print(\"Number of UNIFORM dataframes loaded:\", len(dataframes_uniform))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"021c209a"},"source":["all_results_uniform = []\n","num_rounds = 3\n","\n","for round_num in range(num_rounds):\n","    print(f\"--- Starting Round {round_num + 1}/{num_rounds} (UNIFORM) ---\")\n","    results_list = []\n","\n","    for df_name, df in dataframes_uniform.items():\n","        print(f\"Processing DataFrame: {df_name}\")\n","        for index, row in df.iterrows():\n","            question = row[\"question\"]\n","            try:\n","                true_answers = eval(row[\"answers\"])\n","                if not isinstance(true_answers, list):\n","                     true_answers = [true_answers]\n","            except Exception as e:\n","                print(f\"Error evaluating answers for row {index} in {df_name}: {e}\")\n","                true_answers = []\n","\n","            privatized_context = row[\"privatized_context\"]\n","            repaired_context = row[\"repaired_context\"]\n","\n","            # Generate answer for privatized context\n","            try:\n","                response_privatized = client.chat.completions.create(\n","                    model=\"gpt-4o-mini\",\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                        {\"role\": \"user\", \"content\": f\"Context: {privatized_context}\\nQuestion: {question}\"}\n","                    ],\n","                    temperature=0.2,\n","                    max_tokens=5,\n","                )\n","                answer_privatized = response_privatized.choices[0].message.content.strip()\n","            except Exception as e:\n","                print(f\"Error generating answer for privatized context in row {index} of {df_name}: {e}\")\n","                answer_privatized = \"\"\n","\n","            # Generate answer for repaired context\n","            try:\n","                response_repaired = client.chat.completions.create(\n","                    model=\"gpt-4o-mini\",\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                        {\"role\": \"user\", \"content\": f\"Context: {repaired_context}\\nQuestion: {question}\"}\n","                    ],\n","                    temperature=0.2,\n","                    max_tokens=5,\n","                )\n","                answer_repaired = response_repaired.choices[0].message.content.strip()\n","            except Exception as e:\n","                print(f\"Error generating answer for repaired context in row {index} of {df_name}: {e}\")\n","                answer_repaired = \"\"\n","\n","            # Evaluate answers\n","            f1_privatized, em_privatized = evaluate_answer(answer_privatized, true_answers)\n","            f1_repaired, em_repaired = evaluate_answer(answer_repaired, true_answers)\n","\n","            # Calculate Cosine Similarity\n","            cosine_privatized = calculate_cosine_similarity(answer_privatized, true_answers, model_sentence)\n","            cosine_repaired = calculate_cosine_similarity(answer_repaired, true_answers, model_sentence)\n","\n","            results_list.append({\n","                \"dataframe\": df_name,\n","                \"question\": question,\n","                \"true_answers\": true_answers,\n","                \"answer_privatized\": answer_privatized,\n","                \"f1_privatized\": f1_privatized,\n","                \"em_privatized\": em_privatized,\n","                \"cosine_privatized\": cosine_privatized,\n","                \"answer_repaired\": answer_repaired,\n","                \"f1_repaired\": f1_repaired,\n","                \"em_repaired\": em_repaired,\n","                \"cosine_repaired\": cosine_repaired,\n","            })\n","    df_round_results = pd.DataFrame(results_list)\n","    all_results_uniform.append(df_round_results)\n","\n","print(f\"\\nFinished {num_rounds} rounds of evaluation for UNIFORM files.\")\n","\n","df_all_results_combined_uniform = pd.concat(all_results_uniform, ignore_index=True)\n","\n","csv_output_path_uniform = \"evaluation_results_uniform_rounds.csv\"\n","df_all_results_combined_uniform.to_csv(csv_output_path_uniform, index=False)\n","\n","print(f\"All evaluation results for UNIFORM files saved to {csv_output_path_uniform}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae3ef53b"},"source":["# Extract epsilon values from the 'dataframe' column\n","df_all_results_combined_uniform['epsilon'] = df_all_results_combined_uniform['dataframe'].apply(lambda x: float(x.split('_')[-1]))\n","\n","# Identify method type for uniform dataframes\n","df_uniform_results = df_all_results_combined_uniform.copy()\n","\n","df_uniform_results['method'] = df_uniform_results['dataframe'].apply(\n","    lambda x: 'Uniform Laplace' if 'laplace' in x.lower() else 'Uniform Polar'\n",")\n","\n","# Aggregate results by epsilon and method\n","df_aggregated_uniform = df_uniform_results.groupby(['epsilon', 'method']).agg(\n","    mean_f1_privatized=('f1_privatized', 'mean'),\n","    std_f1_privatized=('f1_privatized', 'std'),\n","    mean_f1_repaired=('f1_repaired', 'mean'),\n","    std_f1_repaired=('f1_repaired', 'std'),\n","    mean_cosine_privatized=('cosine_privatized', 'mean'),\n","    std_cosine_privatized=('cosine_privatized', 'std'),\n","    mean_cosine_repaired=('cosine_repaired', 'mean'),\n","    std_cosine_repaired=('cosine_repaired', 'std')\n",").reset_index()\n","\n","# Sort by epsilon to ensure correct line plotting\n","df_aggregated_uniform = df_aggregated_uniform.sort_values('epsilon')\n","\n","# --- Plot Average Cosine Similarity (Privatized Context) vs. Epsilon for Uniform Methods with Capped Standard Deviation ---\n","plt.figure(figsize=(12, 7))\n","\n","# Plot for Uniform Laplace\n","df_uniform_laplace = df_aggregated_uniform[df_aggregated_uniform['method'] == 'Uniform Laplace']\n","y_uniform_laplace = df_uniform_laplace['mean_cosine_privatized']\n","yerr_uniform_laplace = df_uniform_laplace['std_cosine_privatized']\n","# Cap the upper error bar at 1\n","upper_error_uniform_laplace = np.minimum(y_uniform_laplace + yerr_uniform_laplace, 1) - y_uniform_laplace\n","lower_error_uniform_laplace = y_uniform_laplace - (y_uniform_laplace - yerr_uniform_laplace)\n","\n","plt.errorbar(\n","    df_uniform_laplace['epsilon'],\n","    y_uniform_laplace,\n","    yerr=[lower_error_uniform_laplace, upper_error_uniform_laplace],\n","    label='Uniform Laplace (Privatized Context)',\n","    marker='o',\n","    capsize=5,\n","    linestyle='-'\n",")\n","\n","# Plot for Uniform Polar\n","df_uniform_polar = df_aggregated_uniform[df_aggregated_uniform['method'] == 'Uniform Polar']\n","y_uniform_polar = df_uniform_polar['mean_cosine_privatized']\n","yerr_uniform_polar = df_uniform_polar['std_cosine_privatized']\n","# Cap the upper error bar at 1\n","upper_error_uniform_polar = np.minimum(y_uniform_polar + yerr_uniform_polar, 1) - y_uniform_polar\n","lower_error_uniform_polar = y_uniform_polar - (y_uniform_polar - yerr_uniform_polar)\n","\n","plt.errorbar(\n","    df_uniform_polar['epsilon'],\n","    y_uniform_polar,\n","    yerr=[lower_error_uniform_polar, upper_error_uniform_polar],\n","    label='Uniform Polar (Privatized Context)',\n","    marker='o',\n","    capsize=5,\n","    linestyle='--'\n",")\n","\n","# Add horizontal line for GPT4 Mask Fill (Privatized Context)\n","# Assuming df_mask_fill_results DataFrame is available from previous steps and average_scores was calculated\n","if 'average_scores' in globals() and 'mean_cosine_privatized' in average_scores:\n","    mean_cosine_mask_fill_privatized = average_scores['mean_cosine_privatized']\n","    plt.axhline(y=mean_cosine_mask_fill_privatized, color='red', linestyle=':', label='GPT4 Mask Fill (Privatized Context)')\n","else:\n","    print(\"Warning: Could not find mask fill average cosine similarity for privatized context.\")\n","\n","\n","plt.title('Average Cosine Similarity (Privatized Context) vs. Epsilon for Uniform Methods (Capped Standard Deviation)')\n","plt.xlabel('Epsilon')\n","plt.ylabel('Average Cosine Similarity Score')\n","plt.grid(True)\n","plt.legend(title='Method and Context')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XNyXK0gT7rZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cc6a196"},"source":["# Load the specific dataset\n","file_path = \"/content/squad_stamp_Laplace_sweep_avg_epsilon_1868.98.csv\"\n","try:\n","    df_specific = pd.read_csv(file_path)\n","    print(f\"Loaded dataset: {file_path}\")\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {file_path}\")\n","    df_specific = None\n","\n","if df_specific is not None:\n","    results_list_specific = []\n","\n","    for index, row in df_specific.iterrows():\n","        question = row[\"question\"]\n","        try:\n","            true_answers = eval(row[\"answers\"])\n","            if not isinstance(true_answers, list):\n","                 true_answers = [true_answers]\n","        except Exception as e:\n","            print(f\"Error evaluating answers for row {index}: {e}\")\n","            true_answers = []\n","\n","        privatized_context = row[\"privatized_context\"]\n","        repaired_context = row[\"repaired_context\"]\n","\n","        # Generate answer for privatized context\n","        try:\n","            response_privatized = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                    {\"role\": \"user\", \"content\": f\"Context: {privatized_context}\\nQuestion: {question}\"}\n","                ],\n","                temperature=0.2,\n","                max_tokens=5, # Limit response to one word, but just in case\n","            )\n","            predicted_answer_privatized = response_privatized.choices[0].message.content.strip()\n","        except Exception as e:\n","            print(f\"Error generating answer for privatized context: {e}\")\n","            predicted_answer_privatized = \"\"\n","\n","\n","        # Generate answer for repaired context\n","        try:\n","            response_repaired = client.chat.completions.create(\n","                model=\"gpt-4o-mini\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Limit your answer to one word.\"},\n","                    {\"role\": \"user\", \"content\": f\"Context: {repaired_context}\\nQuestion: {question}\"}\n","                ],\n","                temperature=0.2,\n","                max_tokens=5, # Limit response to one word, but just in case\n","            )\n","            predicted_answer_repaired = response_repaired.choices[0].message.content.strip()\n","        except Exception as e:\n","            print(f\"Error generating answer for repaired context: {e}\")\n","            predicted_answer_repaired = \"\"\n","\n","\n","        # Calculate Cosine Similarity using the pre-trained model_sentence\n","        cosine_privatized = calculate_cosine_similarity(predicted_answer_privatized, true_answers, model_sentence)\n","        cosine_repaired = calculate_cosine_similarity(predicted_answer_repaired, true_answers, model_sentence)\n","\n","        results_list_specific.append({\n","            \"question\": question,\n","            \"true_answers\": true_answers,\n","            \"answer_privatized\": predicted_answer_privatized,\n","            \"cosine_privatized\": cosine_privatized,\n","            \"answer_repaired\": predicted_answer_repaired,\n","            \"cosine_repaired\": cosine_repaired,\n","        })\n","\n","    df_specific_results = pd.DataFrame(results_list_specific)\n","\n","    # Calculate average cosine similarity\n","    average_cosine_privatized = df_specific_results['cosine_privatized'].mean()\n","    average_cosine_repaired = df_specific_results['cosine_repaired'].mean()\n","\n","    print(f\"\\nAverage Cosine Similarity for {file_path}:\")\n","    print(f\"  Privatized Context: {average_cosine_privatized:.4f}\")\n","    print(f\"  Repaired Context: {average_cosine_repaired:.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"05Wzc6pNKNHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uiK2gUYnKNJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_Dhy5z5wKNMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3h-zGvtRQMsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5eHnvB6uQMvO"},"execution_count":null,"outputs":[]}]}